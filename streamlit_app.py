#!/usr/bin/env python3
"""
åšæ±å·ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç›£è¦–ã‚·ã‚¹ãƒ†ãƒ  - Streamlitã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³
å±±å£çœŒå®‡éƒ¨å¸‚ã®åšæ±å·ãƒ€ãƒ ãŠã‚ˆã³åšæ±å·ï¼ˆæŒä¸–å¯ºï¼‰ã®ç›£è¦–ãƒ‡ãƒ¼ã‚¿ã‚’è¡¨ç¤º
"""

import json
import os
import time
from datetime import datetime, timedelta, timezone
from pathlib import Path
from typing import Dict, Any, List, Optional
import pandas as pd
try:
    from zoneinfo import ZoneInfo
except ImportError:
    # Python 3.8ä»¥å‰ã®å ´åˆ
    import pytz
    ZoneInfo = lambda x: pytz.timezone(x)
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import streamlit as st

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(
    page_title="åšæ±å·ç›£è¦–ã‚·ã‚¹ãƒ†ãƒ ",
    page_icon="ğŸŒŠ",
    layout="wide",
    initial_sidebar_state="expanded"
)

class KotogawaMonitor:
    def __init__(self):
        self.base_dir = Path(__file__).parent
        self.data_dir = self.base_dir / "data"
        self.history_dir = self.data_dir / "history"
        
        # ã‚¢ãƒ©ãƒ¼ãƒˆé–¾å€¤ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ï¼‰
        self.default_thresholds = {
            'river_warning': 3.0,
            'river_danger': 5.0,
            'dam_warning': 90.0,
            'dam_danger': 95.0
        }
    
    def load_latest_data(_self) -> Optional[Dict[str, Any]]:
        """æœ€æ–°ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€ï¼ˆãƒ•ã‚¡ã‚¤ãƒ«æ›´æ–°æ™‚åˆ»ãƒ™ãƒ¼ã‚¹ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥ï¼‰"""
        latest_file = _self.data_dir / "latest.json"
        
        if not latest_file.exists():
            st.warning("âš ï¸ ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ãƒ‡ãƒ¼ã‚¿åé›†ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
            return None
        
        try:
            # ãƒ•ã‚¡ã‚¤ãƒ«æ›´æ–°æ™‚åˆ»ã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚­ãƒ¼ã¨ã—ã¦ä½¿ç”¨
            file_mtime = latest_file.stat().st_mtime
            return _self._load_latest_data_cached(str(latest_file), file_mtime)
        except Exception as e:
            st.error(f"âŒ ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    @st.cache_data(ttl=300)  # ãƒ•ã‚¡ã‚¤ãƒ«æ›´æ–°æ™‚åˆ»ãŒå¤‰ã‚ã‚‹ã¾ã§ã‚­ãƒ£ãƒƒã‚·ãƒ¥
    def _load_latest_data_cached(_self, file_path: str, file_mtime: float) -> Optional[Dict[str, Any]]:
        """ãƒ•ã‚¡ã‚¤ãƒ«æ›´æ–°æ™‚åˆ»ã‚’ã‚­ãƒ¼ã¨ã™ã‚‹ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
                
                # ãƒ‡ãƒ¼ã‚¿ã®æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯
                if not data or 'timestamp' not in data:
                    st.error("âŒ ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã®å½¢å¼ãŒæ­£ã—ãã‚ã‚Šã¾ã›ã‚“")
                    return None
                
                return data
        except json.JSONDecodeError as e:
            st.error(f"âŒ JSONãƒ•ã‚¡ã‚¤ãƒ«ã®å½¢å¼ã‚¨ãƒ©ãƒ¼: {e}")
            return None
        except FileNotFoundError:
            st.warning("âš ï¸ ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return None
        except Exception as e:
            st.error(f"âŒ ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def get_cache_key(self) -> str:
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚­ãƒ¼ç”¨ã®æœ€æ–°ãƒ•ã‚¡ã‚¤ãƒ«æ™‚åˆ»ã‚’å–å¾—"""
        try:
            # latest.jsonã®æ›´æ–°æ™‚åˆ»ã‚’å–å¾—
            latest_file = self.data_dir / "latest.json"
            if latest_file.exists():
                return str(latest_file.stat().st_mtime)
            return "no_file"
        except Exception:
            return "error"
    
    @st.cache_data(ttl=300)  # 5åˆ†é–“ã‚­ãƒ£ãƒƒã‚·ãƒ¥ï¼ˆçŸ­ç¸®ï¼‰
    def load_history_data(_self, hours: int = 24, cache_key: str = None) -> List[Dict[str, Any]]:
        """å±¥æ­´ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€"""
        history_data = []
        # JSTï¼ˆæ—¥æœ¬æ¨™æº–æ™‚ï¼‰ã§ç¾åœ¨æ™‚åˆ»ã‚’å–å¾—
        end_time = datetime.now(ZoneInfo('Asia/Tokyo'))
        start_time = end_time - timedelta(hours=hours)
        
        if not _self.history_dir.exists():
            st.info("ğŸ“ å±¥æ­´ãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒã‚ã‚Šã¾ã›ã‚“ã€‚ãƒ‡ãƒ¼ã‚¿ãŒè“„ç©ã•ã‚Œã‚‹ã¾ã§ãŠå¾…ã¡ãã ã•ã„ã€‚")
            return history_data
        
        error_count = 0
        processed_files = 0
        max_files = 100  # æœ€å¤§å‡¦ç†ãƒ•ã‚¡ã‚¤ãƒ«æ•°åˆ¶é™
        
        # JSTæ™‚åˆ»ã§æ—¥ä»˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’å‡¦ç†ï¼ˆæ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰é€†é †ã§å‡¦ç†ï¼‰
        current_time = end_time
        while current_time >= start_time and processed_files < max_files:
            date_dir = (_self.history_dir / 
                       current_time.strftime("%Y") / 
                       current_time.strftime("%m") / 
                       current_time.strftime("%d"))
            
            if date_dir.exists():
                # ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é™é †ã§ã‚½ãƒ¼ãƒˆã—ã¦æ–°ã—ã„ã‚‚ã®ã‹ã‚‰å‡¦ç†
                json_files = sorted(date_dir.glob("*.json"), reverse=True)
                for file_path in json_files:
                    if processed_files >= max_files:
                        break
                    
                    try:
                        with open(file_path, 'r', encoding='utf-8') as f:
                            data = json.load(f)
                            
                            # ãƒ‡ãƒ¼ã‚¿ã®åŸºæœ¬æ¤œè¨¼ã¨JSTæ™‚åˆ»ã§ã®ç¯„å›²ãƒã‚§ãƒƒã‚¯
                            if data and 'timestamp' in data:
                                # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’JSTã§è§£æ
                                try:
                                    data_timestamp = datetime.fromisoformat(data['timestamp'].replace('Z', '+00:00'))
                                    if data_timestamp.tzinfo is None:
                                        data_timestamp = data_timestamp.replace(tzinfo=ZoneInfo('Asia/Tokyo'))
                                    else:
                                        data_timestamp = data_timestamp.astimezone(ZoneInfo('Asia/Tokyo'))
                                    
                                    # æŒ‡å®šæœŸé–“å†…ã®ãƒ‡ãƒ¼ã‚¿ã®ã¿è¿½åŠ 
                                    if start_time <= data_timestamp <= end_time:
                                        history_data.append(data)
                                        processed_files += 1
                                    
                                except Exception as e:
                                    # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—è§£æã‚¨ãƒ©ãƒ¼ã®å ´åˆã‚‚è¿½åŠ ï¼ˆå¾Œæ–¹äº’æ›æ€§ï¼‰
                                    history_data.append(data)
                                    processed_files += 1
                            else:
                                error_count += 1
                                
                    except json.JSONDecodeError:
                        error_count += 1
                        if error_count <= 3:  # æœ€åˆã®3å›ã ã‘è­¦å‘Šè¡¨ç¤º
                            st.warning(f"âš ï¸ ç ´æã—ãŸå±¥æ­´ãƒ•ã‚¡ã‚¤ãƒ«: {file_path.name}")
                    except Exception as e:
                        error_count += 1
                        if error_count <= 3:
                            st.warning(f"âš ï¸ å±¥æ­´ãƒ‡ãƒ¼ã‚¿ã‚¨ãƒ©ãƒ¼: {file_path.name}")
            
            current_time -= timedelta(days=1)
        
        # ã‚¨ãƒ©ãƒ¼ã‚µãƒãƒªãƒ¼è¡¨ç¤º
        if error_count > 3:
            st.warning(f"âš ï¸ å±¥æ­´ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã§ {error_count} ä»¶ã®ã‚¨ãƒ©ãƒ¼ãŒã‚ã‚Šã¾ã—ãŸ")
        
        # æ™‚ç³»åˆ—é †ã«ã‚½ãƒ¼ãƒˆ
        try:
            history_data.sort(key=lambda x: x.get('timestamp', ''))
        except Exception as e:
            st.error(f"âŒ å±¥æ­´ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
            
        return history_data
    
    def check_alert_status(self, data: Dict[str, Any], thresholds: Dict[str, float]) -> Dict[str, str]:
        """ã‚¢ãƒ©ãƒ¼ãƒˆçŠ¶æ…‹ã‚’ãƒã‚§ãƒƒã‚¯"""
        alerts = {
            'river': 'æ­£å¸¸',
            'dam': 'æ­£å¸¸',
            'rainfall': 'æ­£å¸¸',
            'overall': 'æ­£å¸¸'
        }
        
        if not data:
            alerts['overall'] = 'ãƒ‡ãƒ¼ã‚¿ãªã—'
            return alerts
        
        alert_level = 0  # 0=æ­£å¸¸, 1=æ³¨æ„, 2=è­¦æˆ’, 3=å±é™º
        
        # æ²³å·æ°´ä½ãƒã‚§ãƒƒã‚¯ï¼ˆå®Ÿéš›ã®ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’ä½¿ç”¨ï¼‰
        river_status = data.get('river', {}).get('status', 'æ­£å¸¸')
        river_level = data.get('river', {}).get('water_level')
        
        if river_status in ['æ°¾æ¿«å±é™º']:
            alerts['river'] = 'å±é™º'
            alert_level = max(alert_level, 3)
        elif river_status in ['é¿é›£åˆ¤æ–­']:
            alerts['river'] = 'é¿é›£åˆ¤æ–­'
            alert_level = max(alert_level, 3)
        elif river_status in ['æ°¾æ¿«æ³¨æ„']:
            alerts['river'] = 'è­¦æˆ’'
            alert_level = max(alert_level, 2)
        elif river_status in ['æ°´é˜²å›£å¾…æ©Ÿ']:
            alerts['river'] = 'æ³¨æ„'
            alert_level = max(alert_level, 1)
        else:
            alerts['river'] = 'æ­£å¸¸'
        
        # ãƒ€ãƒ æ°´ä½ãƒã‚§ãƒƒã‚¯
        dam_level = data.get('dam', {}).get('water_level')
        
        if dam_level is not None:
            # ãƒ€ãƒ æ°´ä½ã«ã‚ˆã‚‹åˆ¤å®š
            if dam_level >= thresholds['dam_danger']:  # è¨­è¨ˆæœ€é«˜æ°´ä½
                alerts['dam'] = 'å±é™º'
                alert_level = max(alert_level, 3)
            elif dam_level >= thresholds['dam_warning']:  # æ´ªæ°´æ™‚æœ€é«˜æ°´ä½
                alerts['dam'] = 'è­¦æˆ’'
                alert_level = max(alert_level, 2)
        
        # é›¨é‡ãƒã‚§ãƒƒã‚¯
        hourly_rain = data.get('rainfall', {}).get('hourly', 0)
        cumulative_rain = data.get('rainfall', {}).get('cumulative', 0)
        
        if hourly_rain >= 50 or cumulative_rain >= 200:
            alerts['rainfall'] = 'å±é™º'
            alert_level = max(alert_level, 3)
        elif hourly_rain >= 30 or cumulative_rain >= 100:
            alerts['rainfall'] = 'è­¦æˆ’'
            alert_level = max(alert_level, 2)
        elif hourly_rain >= 10 or cumulative_rain >= 50:
            alerts['rainfall'] = 'æ³¨æ„'
            alert_level = max(alert_level, 1)
        
        # ç·åˆã‚¢ãƒ©ãƒ¼ãƒˆãƒ¬ãƒ™ãƒ«è¨­å®š
        if alert_level >= 3:
            alerts['overall'] = 'å±é™º'
        elif alert_level >= 2:
            alerts['overall'] = 'è­¦æˆ’'
        elif alert_level >= 1:
            alerts['overall'] = 'æ³¨æ„'
        else:
            alerts['overall'] = 'æ­£å¸¸'
        
        return alerts
    
    def create_weather_forecast_display(self, data: Dict[str, Any]) -> None:
        """å¤©æ°—äºˆå ±æƒ…å ±ã‚’è¡¨ç¤ºã™ã‚‹"""
        st.markdown("## ğŸŒ¤ï¸ å¤©æ°—äºˆå ±ï¼ˆå®‡éƒ¨å¸‚ï¼‰")
        
        weather_data = data.get('weather', {})
        
        if not weather_data or not weather_data.get('today', {}).get('weather_text'):
            st.info("âš ï¸ å¤©æ°—äºˆå ±ãƒ‡ãƒ¼ã‚¿ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“")
            return
        
        # æ›´æ–°æ™‚åˆ»ã®è¡¨ç¤º
        if weather_data.get('update_time'):
            try:
                update_time = datetime.fromisoformat(weather_data['update_time'])
                st.caption(f"äºˆå ±æ›´æ–°æ™‚åˆ»: {update_time.strftime('%Y-%m-%d %H:%M')} JST")
            except:
                pass
        
        # ä»Šæ—¥ãƒ»æ˜æ—¥ãƒ»æ˜å¾Œæ—¥ã®å¤©æ°—äºˆå ±ã‚’æ¨ªä¸¦ã³ã§è¡¨ç¤º
        col1, col2, col3 = st.columns(3)
        
        # ä»Šæ—¥ã®å¤©æ°—
        with col1:
            st.markdown("### ä»Šæ—¥")
            today = weather_data.get('today', {})
            
            # å¤©æ°—
            weather_text = today.get('weather_text', 'ãƒ‡ãƒ¼ã‚¿ãªã—')
            st.markdown(f"**å¤©æ°—:** {weather_text}")
            
            # æ°—æ¸©
            temp_max = today.get('temp_max')
            temp_min = today.get('temp_min')
            if temp_max is not None and temp_min is not None:
                st.markdown(f"**æ°—æ¸©:** {temp_max}Â°C / {temp_min}Â°C")
            elif temp_max is not None:
                st.markdown(f"**æœ€é«˜æ°—æ¸©:** {temp_max}Â°C")
            elif temp_min is not None:
                st.markdown(f"**æœ€ä½æ°—æ¸©:** {temp_min}Â°C")
            
            # æ™‚é–“åˆ¥é™æ°´ç¢ºç‡
            precip_prob = today.get('precipitation_probability', [])
            precip_times = today.get('precipitation_times', [])
            if precip_prob and precip_times:
                st.markdown(f"**é™æ°´ç¢ºç‡:**")
                for time, prob in zip(precip_times, precip_prob):
                    if prob is not None:
                        st.markdown(f"ã€€{time}: {prob}%")
                    else:
                        st.markdown(f"ã€€{time}: --")
        
        # æ˜æ—¥ã®å¤©æ°—
        with col2:
            st.markdown("### æ˜æ—¥")
            tomorrow = weather_data.get('tomorrow', {})
            
            # å¤©æ°—
            weather_text = tomorrow.get('weather_text', 'ãƒ‡ãƒ¼ã‚¿ãªã—')
            st.markdown(f"**å¤©æ°—:** {weather_text}")
            
            # æ°—æ¸©
            temp_max = tomorrow.get('temp_max')
            temp_min = tomorrow.get('temp_min')
            if temp_max is not None and temp_min is not None:
                st.markdown(f"**æ°—æ¸©:** {temp_max}Â°C / {temp_min}Â°C")
            elif temp_max is not None:
                st.markdown(f"**æœ€é«˜æ°—æ¸©:** {temp_max}Â°C")
            elif temp_min is not None:
                st.markdown(f"**æœ€ä½æ°—æ¸©:** {temp_min}Â°C")
            
            # æ™‚é–“åˆ¥é™æ°´ç¢ºç‡
            precip_prob = tomorrow.get('precipitation_probability', [])
            precip_times = tomorrow.get('precipitation_times', [])
            if precip_prob and precip_times:
                st.markdown(f"**é™æ°´ç¢ºç‡:**")
                for time, prob in zip(precip_times, precip_prob):
                    if prob is not None:
                        st.markdown(f"ã€€{time}: {prob}%")
                    else:
                        st.markdown(f"ã€€{time}: --")
        
        # æ˜å¾Œæ—¥ã®å¤©æ°—
        with col3:
            st.markdown("### æ˜å¾Œæ—¥")
            day_after = weather_data.get('day_after_tomorrow', {})
            
            # å¤©æ°—
            weather_text = day_after.get('weather_text', 'ãƒ‡ãƒ¼ã‚¿ãªã—')
            st.markdown(f"**å¤©æ°—:** {weather_text}")
            
            # æ°—æ¸©
            temp_max = day_after.get('temp_max')
            temp_min = day_after.get('temp_min')
            if temp_max is not None and temp_min is not None:
                st.markdown(f"**æ°—æ¸©:** {temp_max}Â°C / {temp_min}Â°C")
            elif temp_max is not None:
                st.markdown(f"**æœ€é«˜æ°—æ¸©:** {temp_max}Â°C")
            elif temp_min is not None:
                st.markdown(f"**æœ€ä½æ°—æ¸©:** {temp_min}Â°C")
            
            # é™æ°´ç¢ºç‡ï¼ˆé€±é–“äºˆå ±ã¯æ—¥ä¸­ã®ã¿ï¼‰
            precip_prob = day_after.get('precipitation_probability', [])
            precip_times = day_after.get('precipitation_times', [])
            if precip_prob and precip_times:
                st.markdown(f"**é™æ°´ç¢ºç‡:**")
                for time, prob in zip(precip_times, precip_prob):
                    if prob is not None:
                        st.markdown(f"ã€€{time}: {prob}%")
                    else:
                        st.markdown(f"ã€€{time}: --")
        
        # è­¦æˆ’ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
        today_precip = weather_data.get('today', {}).get('precipitation_probability', [])
        tomorrow_precip = weather_data.get('tomorrow', {}).get('precipitation_probability', [])
        day_after_precip = weather_data.get('day_after_tomorrow', {}).get('precipitation_probability', [])
        
        # 3æ—¥é–“ã®æœ€å¤§é™æ°´ç¢ºç‡ã‚’å–å¾—
        max_today = max([p for p in today_precip if p is not None], default=0)
        max_tomorrow = max([p for p in tomorrow_precip if p is not None], default=0)
        max_day_after = max([p for p in day_after_precip if p is not None], default=0)
        
        if max_today >= 70 or max_tomorrow >= 70 or max_day_after >= 70:
            st.warning("âš ï¸ é™æ°´ç¢ºç‡ãŒé«˜ããªã£ã¦ã„ã¾ã™ã€‚æ°´ä½ã®å¤‰åŒ–ã«ã”æ³¨æ„ãã ã•ã„ã€‚")
        elif max_today >= 50 or max_tomorrow >= 50 or max_day_after >= 50:
            st.info("ğŸ’§ é™æ°´ã®å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚æ²³å·ãƒ»ãƒ€ãƒ ã®çŠ¶æ³ã‚’å®šæœŸçš„ã«ã”ç¢ºèªãã ã•ã„ã€‚")
        
        st.markdown("---")
        
        # é€±é–“äºˆå ±ã®è¡¨ç¤º
        self.create_weekly_forecast_display(data)
    
    def create_weekly_forecast_display(self, data: Dict[str, Any]) -> None:
        """é€±é–“äºˆå ±æƒ…å ±ã‚’è¡¨ç¤ºã™ã‚‹"""
        weather_data = data.get('weather', {})
        weekly_forecast = weather_data.get('weekly_forecast', [])
        
        if not weekly_forecast:
            return
        
        st.markdown("## ğŸ“… é€±é–“å¤©æ°—äºˆå ±ï¼ˆå±±å£çœŒï¼‰")
        
        # é€±é–“äºˆå ±ã‚’è¡¨å½¢å¼ã§è¡¨ç¤º
        if len(weekly_forecast) >= 7:
            # 7åˆ—ã«åˆ†ã‘ã¦è¡¨ç¤º
            cols = st.columns(7)
            
            for i, day_data in enumerate(weekly_forecast[:7]):
                with cols[i]:
                    # æ—¥ä»˜ã¨æ›œæ—¥
                    try:
                        date_obj = datetime.strptime(day_data['date'], '%Y-%m-%d')
                        month_day = date_obj.strftime('%m/%d')
                        day_of_week = day_data.get('day_of_week', date_obj.strftime('%a'))
                        
                        # ä»Šæ—¥ãƒ»æ˜æ—¥ãƒ»æ˜å¾Œæ—¥ã®ãƒ©ãƒ™ãƒ«
                        jst = ZoneInfo('Asia/Tokyo')
                        today = datetime.now(jst).date()
                        target_date = date_obj.date()
                        
                        if target_date == today:
                            day_label = "ä»Šæ—¥"
                        elif target_date == today + timedelta(days=1):
                            day_label = "æ˜æ—¥"
                        elif target_date == today + timedelta(days=2):
                            day_label = "æ˜å¾Œæ—¥"
                        else:
                            day_label = day_of_week
                        
                        st.markdown(f"**{month_day}**")
                        st.markdown(f"**{day_label}**")
                    except:
                        st.markdown(f"**{day_data.get('date', '')}**")
                    
                    # å¤©æ°—
                    weather_text = day_data.get('weather_text', 'ãƒ‡ãƒ¼ã‚¿ãªã—')
                    # é•·ã„å¤©æ°—äºˆå ±æ–‡ã‚’çŸ­ç¸®
                    if len(weather_text) > 8:
                        weather_short = weather_text.replace('æ™‚ã€…', 'æ™‚ã€…').replace('ä¸€æ™‚', 'ä¸€æ™‚')[:8] + "..."
                    else:
                        weather_short = weather_text
                    st.markdown(f"{weather_short}")
                    
                    # é™æ°´ç¢ºç‡
                    precip_prob = day_data.get('precipitation_probability')
                    if precip_prob is not None:
                        # é«˜ã„é™æ°´ç¢ºç‡ã¯è‰²ã‚’å¤‰ãˆã‚‹
                        if precip_prob >= 70:
                            st.markdown(f"ğŸŒ§ï¸ **{precip_prob}%**")
                        elif precip_prob >= 50:
                            st.markdown(f"â˜” **{precip_prob}%**")
                        elif precip_prob >= 30:
                            st.markdown(f"ğŸŒ¤ï¸ {precip_prob}%")
                        else:
                            st.markdown(f"â˜€ï¸ {precip_prob}%")
                    else:
                        st.markdown("--")
        
        st.markdown("---")
    
    def create_metrics_display(self, data: Dict[str, Any]) -> None:
        """ç¾åœ¨ã®çŠ¶æ³è¡¨ç¤ºã‚’ä½œæˆ"""
        if not data:
            st.warning("è¡¨ç¤ºã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
            return
        
        # è¦³æ¸¬æ™‚åˆ»ã®å–å¾—ï¼ˆæ—¥æœ¬æ™‚é–“ã§è¡¨ç¤ºï¼‰
        observation_time = data.get('data_time')
        if observation_time:
            try:
                # ISOãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‹ã‚‰æ—¥æ™‚ã‚’è§£æ
                dt = datetime.fromisoformat(observation_time.replace('Z', '+00:00'))
                # ã‚¿ã‚¤ãƒ ã‚¾ãƒ¼ãƒ³ãŒãªã„å ´åˆã¯æ—¥æœ¬æ™‚é–“ã¨ã—ã¦æ‰±ã†
                if dt.tzinfo is None:
                    dt = dt.replace(tzinfo=ZoneInfo('Asia/Tokyo'))
                else:
                    # UTCã‹ã‚‰æ—¥æœ¬æ™‚é–“ã«å¤‰æ›
                    dt = dt.astimezone(ZoneInfo('Asia/Tokyo'))
                obs_time_str = dt.strftime('%Y/%m/%d %H:%M')
            except:
                obs_time_str = observation_time
        else:
            obs_time_str = "ä¸æ˜"
        
        # 3ã¤ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã«åˆ†ã‘ã¦è¡¨ç¤º
        st.subheader("ğŸ“Š ç¾åœ¨ã®è¦³æ¸¬çŠ¶æ³")
        
        # é™é›¨æƒ…å ±
        st.markdown("### ğŸŒ§ï¸ é™é›¨æƒ…å ±")
        rain_col1, rain_col2, rain_col3 = st.columns(3)
        
        with rain_col1:
            hourly_rain = data.get('rainfall', {}).get('hourly')
            if hourly_rain is not None:
                rain_color = "normal"
                if hourly_rain > 20:
                    rain_color = "inverse"
                st.metric(
                    label="60åˆ†é›¨é‡ (mm)",
                    value=f"{hourly_rain}",
                    delta=data.get('rainfall', {}).get('change'),
                    delta_color=rain_color
                )
                if hourly_rain > 30:
                    st.error("ğŸŒ§ï¸ å¤§é›¨æ³¨æ„")
                elif hourly_rain > 10:
                    st.warning("ğŸŒ¦ï¸ é›¨é‡å¤šã‚")
            else:
                st.metric(label="60åˆ†é›¨é‡ (mm)", value="--")
        
        with rain_col2:
            cumulative_rain = data.get('rainfall', {}).get('cumulative')
            if cumulative_rain is not None:
                st.metric(
                    label="ç´¯ç©é›¨é‡ (mm)",
                    value=f"{cumulative_rain}"
                )
            else:
                st.metric(label="ç´¯ç©é›¨é‡ (mm)", value="--")
        
        with rain_col3:
            st.metric(
                label="è¦³æ¸¬æ—¥æ™‚",
                value=obs_time_str
            )
        
        # æ²³å·æƒ…å ±
        st.markdown("### ğŸŒŠ æ²³å·æƒ…å ±ï¼ˆæŒä¸–å¯ºï¼‰")
        river_col1, river_col2, river_col3 = st.columns(3)
        
        with river_col1:
            river_level = data.get('river', {}).get('water_level')
            river_status = data.get('river', {}).get('status', 'æ­£å¸¸')
            if river_level is not None:
                delta_color = "normal"
                level_change = data.get('river', {}).get('level_change')
                if level_change and level_change > 0:
                    delta_color = "inverse"
                elif level_change and level_change < 0:
                    delta_color = "normal"
                
                st.metric(
                    label="æ°´ä½ (m)",
                    value=f"{river_level:.2f}",
                    delta=f"{level_change:.2f}" if level_change is not None else None,
                    delta_color=delta_color
                )
                
                # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹è¡¨ç¤º
                if river_status != 'æ­£å¸¸':
                    if river_status in ['æ°¾æ¿«å±é™º', 'é¿é›£åˆ¤æ–­']:
                        st.error(f"ğŸš¨ {river_status}")
                    elif river_status in ['æ°¾æ¿«æ³¨æ„', 'æ°´é˜²å›£å¾…æ©Ÿ']:
                        st.warning(f"âš ï¸ {river_status}")
                else:
                    st.success(f"âœ… {river_status}")
            else:
                st.metric(label="æ°´ä½ (m)", value="--")
        
        with river_col2:
            st.metric(
                label="è¦³æ¸¬åœ°ç‚¹",
                value="æŒä¸–å¯º"
            )
        
        with river_col3:
            st.metric(
                label="è¦³æ¸¬æ—¥æ™‚",
                value=obs_time_str
            )
        
        # ãƒ€ãƒ æƒ…å ±
        st.markdown("### ğŸ”ï¸ ãƒ€ãƒ æƒ…å ±ï¼ˆåšæ±å·ãƒ€ãƒ ï¼‰")
        dam_col1, dam_col2, dam_col3, dam_col4, dam_col5 = st.columns(5)
        
        with dam_col1:
            dam_level = data.get('dam', {}).get('water_level')
            if dam_level is not None:
                st.metric(
                    label="è²¯æ°´ä½ (m)",
                    value=f"{dam_level:.2f}",
                    delta=data.get('dam', {}).get('storage_change')
                )
            else:
                st.metric(label="è²¯æ°´ä½ (m)", value="--")
        
        with dam_col2:
            storage_rate = data.get('dam', {}).get('storage_rate')
            if storage_rate is not None:
                st.metric(
                    label="è²¯æ°´ç‡ (%)",
                    value=f"{storage_rate:.1f}"
                )
            else:
                st.metric(label="è²¯æ°´ç‡ (%)", value="--")
        
        with dam_col3:
            inflow = data.get('dam', {}).get('inflow')
            if inflow is not None:
                st.metric(
                    label="æµå…¥é‡ (mÂ³/s)",
                    value=f"{inflow:.2f}"
                )
            else:
                st.metric(label="æµå…¥é‡ (mÂ³/s)", value="--")
        
        with dam_col4:
            outflow = data.get('dam', {}).get('outflow')
            if outflow is not None:
                st.metric(
                    label="å…¨æ”¾æµé‡ (mÂ³/s)",
                    value=f"{outflow:.2f}"
                )
            else:
                st.metric(label="å…¨æ”¾æµé‡ (mÂ³/s)", value="--")
        
        with dam_col5:
            st.metric(
                label="è¦³æ¸¬æ—¥æ™‚",
                value=obs_time_str
            )
    
    def create_river_water_level_graph(self, history_data: List[Dict[str, Any]]) -> go.Figure:
        """æ²³å·æ°´ä½ã‚°ãƒ©ãƒ•ã‚’ä½œæˆï¼ˆæ²³å·æ°´ä½ + ãƒ€ãƒ å…¨æ”¾æµé‡ã®äºŒè»¸è¡¨ç¤ºï¼‰"""
        if not history_data:
            fig = go.Figure()
            fig.add_annotation(
                text="è¡¨ç¤ºã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“",
                xref="paper", yref="paper",
                x=0.5, y=0.5, showarrow=False
            )
            return fig
        
        # ãƒ‡ãƒ¼ã‚¿ã‚’DataFrameã«å¤‰æ›
        df_data = []
        for item in history_data:
            # è¦³æ¸¬æ™‚åˆ»ï¼ˆdata_timeï¼‰ã‚’ä½¿ç”¨ã€ãªã‘ã‚Œã°timestampã‚’ä½¿ç”¨
            data_time = item.get('data_time') or item.get('timestamp', '')
            try:
                dt = datetime.fromisoformat(data_time.replace('Z', '+00:00'))
                # ã‚¿ã‚¤ãƒ ã‚¾ãƒ¼ãƒ³ãŒãªã„å ´åˆã¯JSTã¨ã—ã¦æ‰±ã†
                if dt.tzinfo is None:
                    dt = dt.replace(tzinfo=ZoneInfo('Asia/Tokyo'))
                else:
                    dt = dt.astimezone(ZoneInfo('Asia/Tokyo'))
            except:
                continue
                
            row = {'timestamp': dt}
            
            # æ²³å·æ°´ä½
            river_level = item.get('river', {}).get('water_level')
            if river_level is not None:
                row['river_level'] = river_level
            
            # ãƒ€ãƒ å…¨æ”¾æµé‡
            outflow = item.get('dam', {}).get('outflow')
            if outflow is not None:
                row['outflow'] = outflow
            
            df_data.append(row)
        
        if not df_data:
            fig = go.Figure()
            fig.add_annotation(
                text="æœ‰åŠ¹ãªãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“",
                xref="paper", yref="paper",
                x=0.5, y=0.5, showarrow=False
            )
            return fig
        
        df = pd.DataFrame(df_data)
        
        # äºŒè»¸ã‚°ãƒ©ãƒ•ã‚’ä½œæˆ
        fig = make_subplots(specs=[[{"secondary_y": True}]])
        
        # æ²³å·æ°´ä½ï¼ˆå·¦è»¸ï¼‰
        if 'river_level' in df.columns:
            fig.add_trace(
                go.Scatter(
                    x=df['timestamp'],
                    y=df['river_level'],
                    mode='lines+markers',
                    name='æ²³å·æ°´ä½ï¼ˆæŒä¸–å¯ºï¼‰',
                    line=dict(color='#1f77b4')
                ),
                secondary_y=False
            )
        
        # ãƒ€ãƒ å…¨æ”¾æµé‡ï¼ˆå³è»¸ï¼‰
        if 'outflow' in df.columns:
            fig.add_trace(
                go.Scatter(
                    x=df['timestamp'],
                    y=df['outflow'],
                    mode='lines+markers',
                    name='å…¨æ”¾æµé‡ï¼ˆåšæ±å·ãƒ€ãƒ ï¼‰',
                    line=dict(color='#d62728')
                ),
                secondary_y=True
            )
        
        # è»¸ã®è¨­å®š
        fig.update_yaxes(
            title_text="æ²³å·æ°´ä½ (m)",
            range=[0, 6],
            dtick=1,
            secondary_y=False
        )
        fig.update_yaxes(
            title_text="å…¨æ”¾æµé‡ (mÂ³/s)",
            range=[0, 900],
            dtick=150,
            secondary_y=True
        )
        
        fig.update_xaxes(title_text="æ™‚åˆ»")
        
        fig.update_layout(
            height=400,
            showlegend=True,
            legend=dict(
                orientation="h",
                yanchor="bottom",
                y=1.02,
                xanchor="right",
                x=1
            ),
            margin=dict(t=30)
        )
        
        return fig
    
    def create_dam_water_level_graph(self, history_data: List[Dict[str, Any]]) -> go.Figure:
        """ãƒ€ãƒ æ°´ä½ã‚°ãƒ©ãƒ•ã‚’ä½œæˆï¼ˆãƒ€ãƒ æ°´ä½ + æ™‚é–“é›¨é‡ã®äºŒè»¸è¡¨ç¤ºï¼‰"""
        if not history_data:
            fig = go.Figure()
            fig.add_annotation(
                text="è¡¨ç¤ºã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“",
                xref="paper", yref="paper",
                x=0.5, y=0.5, showarrow=False
            )
            return fig
        
        # ãƒ‡ãƒ¼ã‚¿ã‚’DataFrameã«å¤‰æ›
        df_data = []
        for item in history_data:
            # è¦³æ¸¬æ™‚åˆ»ï¼ˆdata_timeï¼‰ã‚’ä½¿ç”¨ã€ãªã‘ã‚Œã°timestampã‚’ä½¿ç”¨
            data_time = item.get('data_time') or item.get('timestamp', '')
            try:
                dt = datetime.fromisoformat(data_time.replace('Z', '+00:00'))
                # ã‚¿ã‚¤ãƒ ã‚¾ãƒ¼ãƒ³ãŒãªã„å ´åˆã¯JSTã¨ã—ã¦æ‰±ã†
                if dt.tzinfo is None:
                    dt = dt.replace(tzinfo=ZoneInfo('Asia/Tokyo'))
                else:
                    dt = dt.astimezone(ZoneInfo('Asia/Tokyo'))
            except:
                continue
                
            row = {'timestamp': dt}
            
            # ãƒ€ãƒ æ°´ä½
            dam_level = item.get('dam', {}).get('water_level')
            if dam_level is not None:
                row['dam_level'] = dam_level
            
            # é›¨é‡
            rainfall = item.get('rainfall', {}).get('hourly')
            if rainfall is not None:
                row['rainfall'] = rainfall
            
            df_data.append(row)
        
        if not df_data:
            fig = go.Figure()
            fig.add_annotation(
                text="æœ‰åŠ¹ãªãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“",
                xref="paper", yref="paper",
                x=0.5, y=0.5, showarrow=False
            )
            return fig
        
        df = pd.DataFrame(df_data)
        
        # äºŒè»¸ã‚°ãƒ©ãƒ•ã‚’ä½œæˆ
        fig = make_subplots(specs=[[{"secondary_y": True}]])
        
        # ãƒ€ãƒ æ°´ä½ï¼ˆå·¦è»¸ï¼‰
        if 'dam_level' in df.columns:
            fig.add_trace(
                go.Scatter(
                    x=df['timestamp'],
                    y=df['dam_level'],
                    mode='lines+markers',
                    name='ãƒ€ãƒ è²¯æ°´ä½ï¼ˆåšæ±å·ãƒ€ãƒ ï¼‰',
                    line=dict(color='#ff7f0e')
                ),
                secondary_y=False
            )
        
        # æ™‚é–“é›¨é‡ï¼ˆå³è»¸ï¼‰
        if 'rainfall' in df.columns:
            fig.add_trace(
                go.Bar(
                    x=df['timestamp'],
                    y=df['rainfall'],
                    name='æ™‚é–“é›¨é‡ï¼ˆå®‡éƒ¨å¸‚ï¼‰',
                    marker_color='#87CEEB',
                    opacity=0.7
                ),
                secondary_y=True
            )
        
        # è»¸ã®è¨­å®š
        fig.update_yaxes(
            title_text="ãƒ€ãƒ è²¯æ°´ä½ (m)",
            range=[0, 50],
            dtick=5,
            secondary_y=False
        )
        fig.update_yaxes(
            title_text="æ™‚é–“é›¨é‡ (mm/h)",
            range=[0, 50],
            dtick=5,
            secondary_y=True
        )
        
        fig.update_xaxes(title_text="æ™‚åˆ»")
        
        fig.update_layout(
            height=400,
            showlegend=True,
            legend=dict(
                orientation="h",
                yanchor="bottom",
                y=1.02,
                xanchor="right",
                x=1
            ),
            margin=dict(t=30)
        )
        
        return fig
    
    def create_dam_flow_graph(self, history_data: List[Dict[str, Any]]) -> go.Figure:
        """ãƒ€ãƒ æµå…¥å‡ºé‡ã‚°ãƒ©ãƒ•ã‚’ä½œæˆï¼ˆæµå…¥é‡ãƒ»å…¨æ”¾æµé‡ + ç´¯åŠ é›¨é‡ã®äºŒè»¸è¡¨ç¤ºï¼‰"""
        if not history_data:
            fig = go.Figure()
            fig.add_annotation(
                text="è¡¨ç¤ºã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“",
                xref="paper", yref="paper",
                x=0.5, y=0.5, showarrow=False
            )
            return fig
        
        # ãƒ‡ãƒ¼ã‚¿ã‚’DataFrameã«å¤‰æ›
        df_data = []
        for item in history_data:
            # è¦³æ¸¬æ™‚åˆ»ï¼ˆdata_timeï¼‰ã‚’ä½¿ç”¨ã€ãªã‘ã‚Œã°timestampã‚’ä½¿ç”¨
            data_time = item.get('data_time') or item.get('timestamp', '')
            try:
                dt = datetime.fromisoformat(data_time.replace('Z', '+00:00'))
                # ã‚¿ã‚¤ãƒ ã‚¾ãƒ¼ãƒ³ãŒãªã„å ´åˆã¯JSTã¨ã—ã¦æ‰±ã†
                if dt.tzinfo is None:
                    dt = dt.replace(tzinfo=ZoneInfo('Asia/Tokyo'))
                else:
                    dt = dt.astimezone(ZoneInfo('Asia/Tokyo'))
            except:
                continue
                
            row = {'timestamp': dt}
            
            # ãƒ€ãƒ æµå…¥é‡
            inflow = item.get('dam', {}).get('inflow')
            if inflow is not None:
                row['inflow'] = inflow
            
            # ãƒ€ãƒ å…¨æ”¾æµé‡
            outflow = item.get('dam', {}).get('outflow')
            if outflow is not None:
                row['outflow'] = outflow
            
            # ç´¯åŠ é›¨é‡
            cumulative_rainfall = item.get('rainfall', {}).get('cumulative')
            if cumulative_rainfall is not None:
                row['cumulative_rainfall'] = cumulative_rainfall
            
            df_data.append(row)
        
        if not df_data:
            fig = go.Figure()
            fig.add_annotation(
                text="æœ‰åŠ¹ãªãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“",
                xref="paper", yref="paper",
                x=0.5, y=0.5, showarrow=False
            )
            return fig
        
        df = pd.DataFrame(df_data)
        
        # äºŒè»¸ã‚°ãƒ©ãƒ•ã‚’ä½œæˆ
        fig = make_subplots(specs=[[{"secondary_y": True}]])
        
        # ãƒ€ãƒ æµå…¥é‡ï¼ˆå·¦è»¸ï¼‰
        if 'inflow' in df.columns:
            fig.add_trace(
                go.Scatter(
                    x=df['timestamp'],
                    y=df['inflow'],
                    mode='lines+markers',
                    name='æµå…¥é‡ï¼ˆåšæ±å·ãƒ€ãƒ ï¼‰',
                    line=dict(color='#2ca02c')
                ),
                secondary_y=False
            )
        
        # ãƒ€ãƒ å…¨æ”¾æµé‡ï¼ˆå·¦è»¸ï¼‰
        if 'outflow' in df.columns:
            fig.add_trace(
                go.Scatter(
                    x=df['timestamp'],
                    y=df['outflow'],
                    mode='lines+markers',
                    name='å…¨æ”¾æµé‡ï¼ˆåšæ±å·ãƒ€ãƒ ï¼‰',
                    line=dict(color='#d62728')
                ),
                secondary_y=False
            )
        
        # ç´¯åŠ é›¨é‡ï¼ˆå³è»¸ï¼‰
        if 'cumulative_rainfall' in df.columns:
            fig.add_trace(
                go.Scatter(
                    x=df['timestamp'],
                    y=df['cumulative_rainfall'],
                    mode='lines+markers',
                    name='ç´¯åŠ é›¨é‡ï¼ˆå®‡éƒ¨å¸‚ï¼‰',
                    line=dict(color='#87CEEB'),
                    fill='tonexty'
                ),
                secondary_y=True
            )
        
        # è»¸ã®è¨­å®š
        fig.update_yaxes(
            title_text="æµé‡ (mÂ³/s)",
            range=[0, 900],
            dtick=100,
            secondary_y=False
        )
        fig.update_yaxes(
            title_text="ç´¯åŠ é›¨é‡ (mm)",
            range=[0, 180],
            dtick=20,
            secondary_y=True
        )
        
        fig.update_xaxes(title_text="æ™‚åˆ»")
        
        fig.update_layout(
            height=400,
            showlegend=True,
            legend=dict(
                orientation="h",
                yanchor="bottom",
                y=1.02,
                xanchor="right",
                x=1
            ),
            margin=dict(t=30)
        )
        
        return fig
    
    def create_data_table(self, history_data: List[Dict[str, Any]]) -> pd.DataFrame:
        """ãƒ‡ãƒ¼ã‚¿ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ä½œæˆ"""
        if not history_data:
            return pd.DataFrame()
        
        table_data = []
        for item in history_data[-20:]:  # æœ€æ–°20ä»¶
            # è¦³æ¸¬æ™‚åˆ»ï¼ˆdata_timeï¼‰ã‚’ä½¿ç”¨ã€ãªã‘ã‚Œã°timestampã‚’ä½¿ç”¨
            data_time = item.get('data_time') or item.get('timestamp', '')
            try:
                dt = datetime.fromisoformat(data_time.replace('Z', '+00:00'))
                # ã‚¿ã‚¤ãƒ ã‚¾ãƒ¼ãƒ³ãŒãªã„å ´åˆã¯JSTã¨ã—ã¦æ‰±ã†
                if dt.tzinfo is None:
                    dt = dt.replace(tzinfo=ZoneInfo('Asia/Tokyo'))
                else:
                    dt = dt.astimezone(ZoneInfo('Asia/Tokyo'))
                formatted_time = dt.strftime('%Y-%m-%d %H:%M')
            except:
                formatted_time = data_time
            
            table_data.append({
                'ãƒ€ãƒ è²¯æ°´ä½(m)': item.get('dam', {}).get('water_level', '--'),
                'ãƒ€ãƒ è²¯æ°´ç‡(%)': item.get('dam', {}).get('storage_rate', '--'),
                'ãƒ€ãƒ æµå…¥é‡(mÂ³/s)': item.get('dam', {}).get('inflow', '--'),
                'ãƒ€ãƒ å…¨æ”¾æµé‡(mÂ³/s)': item.get('dam', {}).get('outflow', '--'),
                'æ°´ä½(m)ï¼ˆæŒä¸–å¯ºï¼‰': item.get('river', {}).get('water_level', '--'),
                'è¦³æ¸¬æ—¥æ™‚': formatted_time
            })
        
        return pd.DataFrame(table_data).iloc[::-1]  # æ–°ã—ã„é †ã«ä¸¦ã³æ›¿ãˆ

def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    monitor = KotogawaMonitor()
    
    # ãƒ˜ãƒƒãƒ€ãƒ¼
    st.title("ğŸŒŠ åšæ±å·ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç›£è¦–ã‚·ã‚¹ãƒ†ãƒ ")
    
    # ã‚µã‚¤ãƒ‰ãƒãƒ¼è¨­å®š
    st.sidebar.header("è¨­å®š")
    
    # è‡ªå‹•æ›´æ–°è¨­å®šï¼ˆä¸€æ™‚çš„ã«ç„¡åŠ¹åŒ–ï¼‰
    # auto_refresh = st.sidebar.checkbox("è‡ªå‹•æ›´æ–° (30ç§’)", value=False)
    # if auto_refresh:
    #     st.rerun()
    
    # è¡¨ç¤ºæœŸé–“è¨­å®š
    display_hours = st.sidebar.selectbox(
        "è¡¨ç¤ºæœŸé–“",
        [6, 12, 24, 48, 72],
        index=2,
        format_func=lambda x: f"{x}æ™‚é–“"
    )
    
    # ã‚¢ãƒ©ãƒ¼ãƒˆé–¾å€¤è¨­å®š
    st.sidebar.subheader("ã‚¢ãƒ©ãƒ¼ãƒˆè¨­å®š")
    river_warning = st.sidebar.number_input("æ²³å·è­¦æˆ’æ°´ä½ (m)", value=3.0, step=0.1)
    river_danger = st.sidebar.number_input("æ²³å·å±é™ºæ°´ä½ (m)", value=5.0, step=0.1)
    dam_warning = st.sidebar.number_input("ãƒ€ãƒ è­¦æˆ’æ°´ä½ (m)", value=39.2, step=0.1, help="æ´ªæ°´æ™‚æœ€é«˜æ°´ä½")
    dam_danger = st.sidebar.number_input("ãƒ€ãƒ å±é™ºæ°´ä½ (m)", value=40.0, step=0.1, help="è¨­è¨ˆæœ€é«˜æ°´ä½")
    
    thresholds = {
        'river_warning': river_warning,
        'river_danger': river_danger,
        'dam_warning': dam_warning,
        'dam_danger': dam_danger
    }
    
    # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    latest_data = monitor.load_latest_data()
    
    # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚­ãƒ¼å–å¾—
    cache_key = monitor.get_cache_key()
    
    # å±¥æ­´ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿
    try:
        with st.spinner("å±¥æ­´ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ä¸­..."):
            history_data = monitor.load_history_data(display_hours, cache_key)
    except Exception as e:
        st.warning(f"å±¥æ­´ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        history_data = []
    
    # æœ€çµ‚æ›´æ–°æ™‚åˆ»ã¨è¦³æ¸¬æ™‚åˆ»è¡¨ç¤º
    col1, col2 = st.columns([3, 1])
    with col1:
        if latest_data and latest_data.get('timestamp'):
            try:
                # ãƒ‡ãƒ¼ã‚¿å–å¾—æ™‚åˆ»ï¼ˆtimestampï¼‰
                timestamp = datetime.fromisoformat(latest_data['timestamp'].replace('Z', '+00:00'))
                # ã‚¿ã‚¤ãƒ ã‚¾ãƒ¼ãƒ³ãŒãªã„å ´åˆã¯æ—¥æœ¬æ™‚é–“ã¨ã—ã¦æ‰±ã†ï¼ˆå¤‰æ›ãªã—ï¼‰
                if timestamp.tzinfo is None:
                    timestamp = timestamp.replace(tzinfo=ZoneInfo('Asia/Tokyo'))
                
                # è¦³æ¸¬æ™‚åˆ»ï¼ˆdata_timeï¼‰
                data_time_str = latest_data.get('data_time', '')
                if data_time_str:
                    data_time = datetime.fromisoformat(data_time_str.replace('Z', '+00:00'))
                    if data_time.tzinfo is None:
                        data_time = data_time.replace(tzinfo=ZoneInfo('Asia/Tokyo'))
                    st.info(f"è¦³æ¸¬æ™‚åˆ»: {data_time.strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M')} | å–å¾—æ™‚åˆ»: {timestamp.strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S')}")
                else:
                    st.info(f"æœ€çµ‚æ›´æ–°: {timestamp.strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S')}")
            except Exception as e:
                st.info(f"æœ€çµ‚æ›´æ–°: {latest_data.get('timestamp', 'ä¸æ˜')} (æ™‚åˆ»è§£æã‚¨ãƒ©ãƒ¼)")
        else:
            st.warning("ãƒ‡ãƒ¼ã‚¿ãŒå–å¾—ã§ãã¦ã„ã¾ã›ã‚“")
    
    with col2:
        if st.button("ğŸ”„ æ›´æ–°", type="primary"):
            # ç‰¹å®šã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥é–¢æ•°ã‚’ã‚¯ãƒªã‚¢
            monitor.load_history_data.clear()
            st.cache_data.clear()
            st.rerun()
    
    # ã‚¢ãƒ©ãƒ¼ãƒˆè¡¨ç¤º
    if latest_data:
        alerts = monitor.check_alert_status(latest_data, thresholds)
        
        # ã‚¢ãƒ©ãƒ¼ãƒˆè©³ç´°æƒ…å ±
        alert_details = []
        if alerts['river'] != 'æ­£å¸¸':
            river_status = latest_data.get('river', {}).get('status', 'ä¸æ˜')
            alert_details.append(f"æ²³å·: {river_status}")
        if alerts['dam'] != 'æ­£å¸¸':
            dam_level = latest_data.get('dam', {}).get('water_level')
            if dam_level is not None:
                alert_details.append(f"ãƒ€ãƒ : {alerts['dam']} ({dam_level:.2f}m)")
            else:
                alert_details.append(f"ãƒ€ãƒ : {alerts['dam']}")
        if alerts['rainfall'] != 'æ­£å¸¸':
            hourly_rain = latest_data.get('rainfall', {}).get('hourly', 0)
            alert_details.append(f"é›¨é‡: {hourly_rain}mm/h")
        
        # ç·åˆã‚¢ãƒ©ãƒ¼ãƒˆè¡¨ç¤º
        if alerts['overall'] == 'å±é™º':
            detail_text = " | ".join(alert_details) if alert_details else ""
            st.error(f"ğŸš¨ **å±é™ºãƒ¬ãƒ™ãƒ«**: ç·Šæ€¥å¯¾å¿œãŒå¿…è¦ã§ã™ {detail_text}")
        elif alerts['overall'] == 'è­¦æˆ’':
            detail_text = " | ".join(alert_details) if alert_details else ""
            st.warning(f"âš ï¸ **è­¦æˆ’ãƒ¬ãƒ™ãƒ«**: æ³¨æ„ãŒå¿…è¦ã§ã™ {detail_text}")
        elif alerts['overall'] == 'æ³¨æ„':
            detail_text = " | ".join(alert_details) if alert_details else ""
            st.info(f"â„¹ï¸ **æ³¨æ„ãƒ¬ãƒ™ãƒ«**: çŠ¶æ³ã‚’ç›£è¦–ä¸­ {detail_text}")
        elif alerts['overall'] == 'æ­£å¸¸':
            st.success("âœ… **æ­£å¸¸ãƒ¬ãƒ™ãƒ«**: å®‰å…¨ãªçŠ¶æ…‹ã§ã™")
        else:
            st.info("â„¹ï¸ ãƒ‡ãƒ¼ã‚¿ç¢ºèªä¸­...")
    
    # ç¾åœ¨ã®çŠ¶æ³è¡¨ç¤º
    monitor.create_metrics_display(latest_data)
    
    # å¤©æ°—äºˆå ±è¡¨ç¤º
    monitor.create_weather_forecast_display(latest_data)
    
    # ã‚¿ãƒ–ã«ã‚ˆã‚‹è¡¨ç¤ºåˆ‡ã‚Šæ›¿ãˆ
    tab1, tab2 = st.tabs(["ğŸ“Š ã‚°ãƒ©ãƒ•", "ğŸ“‹ ãƒ‡ãƒ¼ã‚¿ãƒ†ãƒ¼ãƒ–ãƒ«"])
    
    with tab1:
        st.subheader("æ²³å·æ°´ä½ãƒ»å…¨æ”¾æµé‡")
        fig1 = monitor.create_river_water_level_graph(history_data)
        st.plotly_chart(fig1, use_container_width=True)
        
        st.subheader("ãƒ€ãƒ æµå…¥å‡ºé‡ãƒ»ç´¯åŠ é›¨é‡")
        fig2 = monitor.create_dam_flow_graph(history_data)
        st.plotly_chart(fig2, use_container_width=True)
        
        st.subheader("ãƒ€ãƒ è²¯æ°´ä½ãƒ»æ™‚é–“é›¨é‡")
        fig3 = monitor.create_dam_water_level_graph(history_data)
        st.plotly_chart(fig3, use_container_width=True)
    
    with tab2:
        st.subheader("ãƒ‡ãƒ¼ã‚¿ãƒ†ãƒ¼ãƒ–ãƒ«")
        df_table = monitor.create_data_table(history_data)
        if not df_table.empty:
            st.dataframe(df_table, use_container_width=True)
            
            # CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
            csv = df_table.to_csv(index=False, encoding='utf-8-sig')
            st.download_button(
                label="ğŸ“¥ CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                data=csv,
                file_name=f"kotogawa_data_{datetime.now().strftime('%Y%m%d_%H%M')}.csv",
                mime="text/csv"
            )
        else:
            st.info("è¡¨ç¤ºã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
    
    # ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±ï¼ˆã‚µã‚¤ãƒ‰ãƒãƒ¼ï¼‰
    st.sidebar.subheader("ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±")
    
    # ãƒ‡ãƒ¼ã‚¿çµ±è¨ˆ
    st.sidebar.info(
        f"ğŸ“Š ãƒ‡ãƒ¼ã‚¿ä»¶æ•°: {len(history_data)}ä»¶\n"
        f"â±ï¸ è¡¨ç¤ºæœŸé–“: {display_hours}æ™‚é–“"
    )
    
    # è­¦æˆ’ãƒ¬ãƒ™ãƒ«èª¬æ˜
    with st.sidebar.expander("ğŸš¨ è­¦æˆ’ãƒ¬ãƒ™ãƒ«èª¬æ˜"):
        st.write(f"""
        **æ²³å·æ°´ä½åŸºæº–**
        - æ­£å¸¸: 3.80mæœªæº€
        - æ°´é˜²å›£å¾…æ©Ÿ: 3.80mä»¥ä¸Š
        - æ°¾æ¿«æ³¨æ„: 5.00mä»¥ä¸Š
        - é¿é›£åˆ¤æ–­: 5.10mä»¥ä¸Š
        - æ°¾æ¿«å±é™º: 5.50mä»¥ä¸Š
        
        **ãƒ€ãƒ æ°´ä½åŸºæº–**
        - è­¦æˆ’: {dam_warning}mä»¥ä¸Šï¼ˆæ´ªæ°´æ™‚æœ€é«˜æ°´ä½ï¼‰
        - å±é™º: {dam_danger}mä»¥ä¸Šï¼ˆè¨­è¨ˆæœ€é«˜æ°´ä½ï¼‰
        
        **é›¨é‡åŸºæº–**
        - æ³¨æ„: 10mm/hä»¥ä¸Š
        - è­¦æˆ’: 30mm/hä»¥ä¸Š
        - å±é™º: 50mm/hä»¥ä¸Š
        """)
    
    # ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹æƒ…å ±
    with st.sidebar.expander("ğŸ“¡ ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹"):
        st.write("""
        **åšæ±å·ãƒ€ãƒ **
        - è¦³æ¸¬åœ°ç‚¹: å®‡éƒ¨å¸‚
        - æ›´æ–°é–“éš”: 10åˆ†
        
        **åšæ±å·(æŒä¸–å¯º)**
        - è¦³æ¸¬åœ°ç‚¹: å®‡éƒ¨å¸‚æŒä¸–å¯º
        - æ›´æ–°é–“éš”: 10åˆ†
        
        ãƒ‡ãƒ¼ã‚¿æä¾›: å±±å£çœŒåœŸæœ¨é˜²ç½æƒ…å ±ã‚·ã‚¹ãƒ†ãƒ 
        """)
    
    # æœ€çµ‚æ›´æ–°ã‹ã‚‰ã®çµŒéæ™‚é–“
    if latest_data and latest_data.get('timestamp'):
        try:
            last_update = datetime.fromisoformat(latest_data['timestamp'].replace('Z', '+00:00'))
            # ã‚¿ã‚¤ãƒ ã‚¾ãƒ¼ãƒ³ãŒãªã„å ´åˆã¯æ—¥æœ¬æ™‚é–“ã¨ã—ã¦æ‰±ã†ï¼ˆå¤‰æ›ãªã—ï¼‰
            if last_update.tzinfo is None:
                last_update = last_update.replace(tzinfo=ZoneInfo('Asia/Tokyo'))
            
            # ç¾åœ¨æ™‚åˆ»ï¼ˆæ—¥æœ¬æ™‚é–“ï¼‰
            now_jst = datetime.now(ZoneInfo('Asia/Tokyo'))
            time_diff = now_jst - last_update
            minutes_ago = int(time_diff.total_seconds() / 60)
            
            if minutes_ago < 60:
                st.sidebar.success(f"ğŸŸ¢ æœ€æ–° ({minutes_ago}åˆ†å‰)")
            elif minutes_ago < 120:
                st.sidebar.warning(f"ğŸŸ¡ ã‚„ã‚„å¤ã„ ({minutes_ago}åˆ†å‰)")
            else:
                st.sidebar.error(f"ğŸ”´ å¤ã„ãƒ‡ãƒ¼ã‚¿ ({minutes_ago}åˆ†å‰)")
        except:
            st.sidebar.info("ğŸ”µ æ›´æ–°æ™‚åˆ»ç¢ºèªä¸­")
    
    # ã‚¢ãƒ—ãƒªæƒ…å ±
    st.sidebar.markdown("---")
    st.sidebar.caption("åšæ±å·ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç›£è¦–ã‚·ã‚¹ãƒ†ãƒ  v1.0")
    st.sidebar.caption("Powered by Streamlit")

if __name__ == "__main__":
    main()